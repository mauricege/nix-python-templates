{% extends pathjoin("includes", "_README.md.jinja") %}

{% block description %}
This folder contains a reproducible development shell powered by [devenv](https://devenv.sh/). It provides a consistent approach to managing system packages, language runtimes, and Python dependencies via {%- if python_package_manager == 'uv'%}[uv](https://github.com/astral-sh/uv){%- elif python_package_manager == 'pip' %}pip{% endif %}.
{% endblock %}

{% block features %}
- Isolated, declarative and reproducible shell environment
- Easily extendable with system packages and languages
- {%- if python_package_manager == 'uv' %}Fast{% endif %} Python dependency management via `{{ python_package_manager }}`{%- if python_package_manager == 'uv' %} and `pyproject.toml`/`{{ python_package_manager }}.lock`{% endif %}
- Automatic environment activation with [direnv](https://direnv.net/)
{% endblock %}

{% block getting_started %}
1. **Install [Nix](https://nixos.org/download.html){%- if interface == 'cli' %}, [devenv](https://devenv.sh/getting-started/){%- endif %} and [direnv](https://direnv.net/docs/installation.html)**
2. Allow direnv in this directory (run once):

    ```sh
    direnv allow
    ```
{% endblock %}

{% block extending_environment %}
### Add System Packages

Edit `{%- if interface == 'flake' %}.nix/{%- endif %}devenv.nix` and add packages to the `packages` list:

```nix
packages = with pkgs; [
  git
  curl
  # Add more packages here
];
```
{% if interface == 'cli' %}
Find packages provided by your inputs (`devenv.yaml`) with `devenv search`. This is slow on the first run, as it has to git-checkout the revision of nixpkgs that your `devenv.lock` points to. You can also utilize `nix-search` a CLI for [search.nixos.org](https://search.nixos.org) - this searches the current maintained nix-channels.
{% else %}
You can use the [NixOS search](https://search.nixos.org/packages) to find packages (or the CLI `nix-search`). Just copy the package name and add it to the `packages` list.
{% endif %}
### Enable Languages

Enable language support by adding to the `languages` section:

```nix
languages.python.enable = true;
languages.nodejs.enable = true;
# Add more languages as needed
```

For a comprehensive list of available language options and their configuration details,
please refer to the official devenv documentation at: <https://devenv.sh/languages/>
{% endblock %}

{% block reusing_environment %}
While I strongly recommend against sharing a development environment across projects - you will lose out on reproducibility and version control, and you might break your older code with future updates to the environment - you can still achieve this by copying over `.envrc.local`:

```sh
cp .envrc.local /your/new/project/.envrc
```

This will source the environment living in your current directory from your new project's root folder.
{% endblock %}

{% block installing_flash_attention %}
{%- if install_flash_attention  %}
flash-attention should already be installed in your environment! If it is not, you can follow the instructions below to install it manually.

{%- endif%}
It's probably best to just update your template and agree to install flash-attention:

```sh
    copier update
```

If you insist on doing it manually, here are the steps:

1. **Ensure `nvcc` is available** by adding it to your `devenv.nix`:

    Edit your `{%- if interface == 'flake' %}.nix/{%- endif %}devenv.nix` to include the correct CUDA version. For example, to use CUDA 12.4:

    ```nix
    let
    # ...
    cudaPackages = pkgs.cudaPackages_12_4;
    # ...
    in
    # ...
    packages = with pkgs; [
      cudaPackages.cuda_nvcc
      git
    ];
    ```

    If you need a different CUDA version (e.g., 11.8), change the line to:

    ```nix
    cudaPackages = pkgs.cudaPackages_11_8;
    ```

    **Make sure the CUDA version here matches the CUDA version of your `torch` build** (e.g., `torch==2.6.0+cu124` for CUDA 12.4).

{%- if python_package_manager == 'pip' %}
2. **Install a compatible `torch` version**  
    Make sure you have the correct version of `torch` for installed that matches your CUDA version. For example, for CUDA 12.4:

    ```sh
    pip install torch==2.6.0+cu124
    ```
    Then install `flash-attn` without build isolation:

    ```sh
    pip install flash-attn --no-build-isolation
    ```
{%- else %}

2. **Add dependencies to `pyproject.toml`**  
    Your `pyproject.toml` should include:

    ```toml
    [project]
    dependencies = []

    [project.optional-dependencies]
    build = ["torch~=2.6.0", "setuptools", "packaging", "psutil", "numpy"]
    compile = ["flash-attn~=2.7.4"]

    [tool.uv]
    no-build-isolation-package = ["flash-attn"]

    [[tool.uv.dependency-metadata]]
    name = "flash-attn"
    requires-dist = ["torch", "einops", "psutil", "numpy"]
    ```

    - The `build` group includes `torch` and related build tools.
    - The `compile` group includes `flash-attn`.

3. **Configure Python and {{ python_package_manager }} in `devenv.nix`**  
    Make sure your `devenv.nix` includes the following to enable Python, {{ python_package_manager }}, and syncing of the `build` and `compile` extras.

    First, adapt the languages section:

    ```nix
    languages = {
        python = {
            enable = true;
            version = "{{ python_version }}";
            manylinux.enable = false;
            libraries = with pkgs; [
                zlib
            ];
            venv.enable = true;
            {%- if python_package_manager == 'uv' %}
            uv = {
                enable = true;
                sync = {
                    enable = true;
                    extras = [ "flash_attention_build" ];
                };
            };
            {%- endif %}
        };
    };
    ```

    Then, create a task to compile flash-attention when entering the shell:

    ```nix
    tasks = {
        "devenv:python:install-flash-attn" = {
            description = "Install Flash Attention";
            exec = "uv sync --extra flash_attention_build --extra flash_attention_compile";
            after = ["devenv:python:uv"];
        };
    };
    ```

    Leave the existing tasks as they are.

    - The `extras = ["build"]` ensures the `build` group is always synced.
    - The `devenv:python:install-flash-attn"` tasks ensures both `build` and `compile` extras are installed when you enter the shell.
    - By enabling the `build` extra as a devenv option for {{ python_package_manager }}, flash-attention's build dependencies will be installed before the compilation task runs.

Now, both `torch` and `flash-attn` will be reproducibly managed by `{{ python_package_manager }}` and installed in your environment whenever you enter the shell.
{%- endif %}
{% endblock %}

{% block resources %}
- [devenv documentation](https://devenv.sh/)
{%- if python_package_manager == 'uv' %}
- [uv documentation](https://docs.astral.sh/uv/)
{%- endif %}
- [direnv documentation](https://direnv.net/)
{%- if python_package_manager == 'uv' %}
- [flash-attn via uv](https://docs.astral.sh/uv/concepts/projects/config/#build-isolation)
{%- endif %}
{% endblock %}

{% block additional %}
### How do I get rid of the cow?

If you are confident that you will remember where to find this readme, you can disable the cowsay output in `{%- if interface == 'flake' %}.nix/{%- endif %}devenv.nix` by modifying `enterShell`:

```nix
enterShell = ''
    # Just remove the line below if you don't want to see the cow
    ${pkgs.cowsay}/bin/cowsay "If you have any questions about installing packages, please check the _README.md file in this directory! (Also if you want to get rid of the cow ;P)" | ${pkgs.lolcat}/bin/lolcat
'';
```

{% endblock %}
